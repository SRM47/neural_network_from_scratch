# Neural Network from Scratch
This repository contains code for the implementation of an artificial deep neural network using only NumPy. The code is not intended to be a replacement for existing neural network frameworks such as PyTorch or TensorFlow, but rather to provide a simple and easy-to-understand example of how neural networks work.

The code includes all of the basic building blocks of an artificial neural network, such as the backpropagation algorithm, optimization with Adam, and loss functions. It also allows users to implement their own components by inheriting from an abstract base class and implementing the new component's respective functions.

The code is well-documented and easy to follow, making it a valuable resource for anyone who wants to learn more about how neural networks work.

To play around with training your own neural network with this interface, run `train.py`
